{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import nni\n",
    "from nni.nas.nn.pytorch import LayerChoice, ModelSpace, MutableDropout, MutableLinear\n",
    "from nni.nas.evaluator.pytorch import Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Shape of X =  (99687, 10, 23) <class 'numpy.ndarray'> float64\n",
      " Shape of y =  (99687,) <class 'numpy.ndarray'> <U1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([6, 1, 6, ..., 3, 4, 5])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes 9\n",
      "torch.Size([59812, 23, 10]) torch.Size([59812, 9])\n"
     ]
    }
   ],
   "source": [
    "from aeon.datasets import load_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.utils.data import TensorDataset #, DataLoader\n",
    "from nni.nas.evaluator.pytorch.lightning import DataLoader\n",
    "from einops import rearrange\n",
    "\n",
    "X, y = load_classification(\"Tiselac\", extract_path=\"/workdir/data\")\n",
    "print(\" Shape of X = \", X.shape, type(X), X.dtype)\n",
    "print(\" Shape of y = \", y.shape, type(y), y.dtype)\n",
    "y = y.astype(int)\n",
    "display(y)\n",
    "\n",
    "X = rearrange(X, \"n v t -> n t v\")\n",
    "in_feat = X.shape[2]\n",
    "\n",
    "# Target\n",
    "y = y - 1\n",
    "y_unique = np.unique(y)\n",
    "num_classes = len(y_unique)\n",
    "print(\"num_classes\", num_classes)\n",
    "y = np.eye(num_classes)[y]\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.40, random_state = 1, stratify = y)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size = 0.50, random_state = 1, stratify = y_test)\n",
    "\n",
    "\n",
    "# Normalize\n",
    "# X_time_train, X_time_val, X_time_test = normalize_across_time(X_time_train, X_time_val, X_time_test, X_time.shape[2])\n",
    "\n",
    "\n",
    "# Datasets\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "# Dataloaders\n",
    "batch_size = 64\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModelSpace(\n",
       "  (layer1): LayerChoice(\n",
       "    label='backbone/layer1'\n",
       "    (0): BottleneckCell(\n",
       "      (linear_in): MutableLinear(in_features=10, out_features=200)\n",
       "      (linear_out): MutableLinear(in_features=200, out_features=100)\n",
       "    )\n",
       "    (1): BottleneckCell(\n",
       "      (linear_in): MutableLinear(in_features=10, out_features=50)\n",
       "      (linear_out): MutableLinear(in_features=50, out_features=100)\n",
       "    )\n",
       "  )\n",
       "  (act1): LayerChoice(\n",
       "    label='backbone/act1'\n",
       "    (0): ReLU()\n",
       "    (1): SELU()\n",
       "  )\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (layer2): LayerChoice(\n",
       "    label='backbone/layer2'\n",
       "    (0): BottleneckCell(\n",
       "      (linear_in): MutableLinear(in_features=2300, out_features=200)\n",
       "      (linear_out): MutableLinear(in_features=200, out_features=100)\n",
       "    )\n",
       "    (1): BottleneckCell(\n",
       "      (linear_in): MutableLinear(in_features=2300, out_features=50)\n",
       "      (linear_out): MutableLinear(in_features=50, out_features=100)\n",
       "    )\n",
       "  )\n",
       "  (act2): LayerChoice(\n",
       "    label='backbone/act2'\n",
       "    (0): ReLU()\n",
       "    (1): SELU()\n",
       "  )\n",
       "  (layer3): Linear(in_features=100, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BottleneckCell(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features):\n",
    "        super(BottleneckCell, self).__init__()\n",
    "\n",
    "        self.linear_in = MutableLinear(in_features, hidden_features)\n",
    "        self.linear_out = MutableLinear(hidden_features, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.linear_out(F.relu(self.linear_in(x)))\n",
    "        return output\n",
    "\n",
    "class MyModelSpace(ModelSpace, label_prefix='backbone'):\n",
    "    def __init__(self, in_feat, hidden_feat, out_feat):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer1 = LayerChoice([\n",
    "            BottleneckCell(in_feat, 200, hidden_feat),\n",
    "            BottleneckCell(in_feat, 50, hidden_feat),\n",
    "        ], label='layer1')\n",
    "        \n",
    "        self.act1 = LayerChoice([\n",
    "            nn.ReLU(),\n",
    "            nn.SELU(),\n",
    "        ], label='act1')\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.layer2 = LayerChoice([\n",
    "            BottleneckCell(23 * hidden_feat, 200, hidden_feat),\n",
    "            BottleneckCell(23 * hidden_feat, 50, hidden_feat),\n",
    "        ], label='layer2')\n",
    "        \n",
    "        self.act2 = LayerChoice([\n",
    "            nn.ReLU(),\n",
    "            nn.SELU(),\n",
    "        ], label='act2')\n",
    "        \n",
    "        self.layer3 = nn.Linear(hidden_feat, out_feat)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.layer1(x))\n",
    "        x = self.flatten(x)\n",
    "        x = self.act2(self.layer2(x))\n",
    "        output = self.layer3(x)\n",
    "        # output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "model_space = MyModelSpace(in_feat, 100, num_classes)\n",
    "model_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 23, 10]) torch.float32 torch.Size([64, 9]) torch.float32\n",
      "torch.Size([64, 9])\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_loader:\n",
    "    print(X.shape, X.dtype, y.shape, y.dtype)\n",
    "    \n",
    "    out = model_space(X)\n",
    "    print(out.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "evaluator = Classification(\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    learning_rate=1e-3,\n",
    "    weight_decay=1e-4,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=val_loader,\n",
    "    max_epochs=10,\n",
    "    gpus=1,\n",
    "    # fast_dev_run=True,\n",
    "    num_classes=num_classes,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nni.nas.strategy import DARTS\n",
    "from nni.nas.strategy import GumbelDARTS\n",
    "strategy = DARTS()\n",
    "\n",
    "# nni.nas.nn.pytorch.LayerChoice.\n",
    "# nni.nas.nn.pytorch.InputChoice.\n",
    "# nni.nas.nn.pytorch.ParametrizedModule (only when parameters are choices and type is in MutableLinear, MutableConv2d, MutableBatchNorm2d, MutableLayerNorm, MutableMultiheadAttention).\n",
    "# nni.nas.nn.pytorch.Repeat.\n",
    "# nni.nas.nn.pytorch.Cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-04 10:57:30] \u001b[32mConfig is not provided. Will try to infer.\u001b[0m\n",
      "[2024-02-04 10:57:30] \u001b[32mStrategy is found to be a one-shot strategy. Setting execution engine to \"sequential\" and format to \"raw\".\u001b[0m\n",
      "[2024-02-04 10:57:30] \u001b[33mWARNING: `training_service` will be ignored for sequential execution engine.\u001b[0m\n",
      "[2024-02-04 10:57:30] \u001b[33mWARNING: `training_service` will be ignored for sequential execution engine.\u001b[0m\n",
      "[2024-02-04 10:57:30] \u001b[33mWARNING: `training_service` will be ignored for sequential execution engine.\u001b[0m\n",
      "[2024-02-04 10:57:30] \u001b[33mWARNING: `training_service` will be ignored for sequential execution engine.\u001b[0m\n",
      "[2024-02-04 10:57:30] \u001b[33mWARNING: `training_service` will be ignored for sequential execution engine.\u001b[0m\n",
      "[2024-02-04 10:57:30] \u001b[33mWARNING: `training_service` will be ignored for sequential execution engine.\u001b[0m\n",
      "[2024-02-04 10:57:30] \u001b[33mWARNING: `training_service` will be ignored for sequential execution engine.\u001b[0m\n",
      "[2024-02-04 10:57:30] \u001b[33mWARNING: `training_service` will be ignored for sequential execution engine.\u001b[0m\n",
      "[2024-02-04 10:57:30] \u001b[33mWARNING: Checkpoint callback does not have last_model_path or best_model_path attribute. Either the strategy has not started, or it did not save any checkpoint: <pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7f64f5a7b4c0>\u001b[0m\n",
      "[2024-02-04 10:57:30] \u001b[33mWARNING: `training_service` will be ignored for sequential execution engine.\u001b[0m\n",
      "[2024-02-04 10:57:30] \u001b[33mWARNING: `training_service` will be ignored for sequential execution engine.\u001b[0m\n",
      "[2024-02-04 10:57:30] \u001b[32mCheckpoint saved to /root/nni-experiments/2wmj9yvs/checkpoint.\u001b[0m\n",
      "[2024-02-04 10:57:30] \u001b[32mExperiment initialized successfully. Starting exploration strategy...\u001b[0m\n",
      "[2024-02-04 10:57:30] \u001b[33mWARNING: Validation dataloaders are missing. Safe to ignore this warning when using one-shot strategy.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
      "\n",
      "  | Name            | Type                 | Params\n",
      "---------------------------------------------------------\n",
      "0 | training_module | ClassificationModule | 629 K \n",
      "---------------------------------------------------------\n",
      "629 K     Trainable params\n",
      "0         Non-trainable params\n",
      "629 K     Total params\n",
      "2.517     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "915e850f72474d1ea8c86b67a61c5f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-04 11:01:05] \u001b[32mWaiting for models submitted to engine to finish...\u001b[0m\n",
      "[2024-02-04 11:01:05] \u001b[32mExperiment is completed.\u001b[0m\n",
      "[2024-02-04 11:01:05] \u001b[33mWARNING: `training_service` will be ignored for sequential execution engine.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nni.nas.experiment import NasExperiment\n",
    "\n",
    "experiment = NasExperiment(model_space, evaluator, strategy)\n",
    "experiment.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'backbone/layer1': 0,\n",
       " 'backbone/act1': 0,\n",
       " 'backbone/layer2': 1,\n",
       " 'backbone/act2': 0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exported_arch = experiment.export_top_models(formatter='dict')[0]\n",
    "exported_arch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | criterion | CrossEntropyLoss | 0     \n",
      "1 | metrics   | ModuleDict       | 0     \n",
      "2 | _model    | MyModelSpace     | 143 K \n",
      "-----------------------------------------------\n",
      "143 K     Trainable params\n",
      "0         Non-trainable params\n",
      "143 K     Total params\n",
      "0.573     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModelSpace(\n",
      "  (layer1): BottleneckCell(\n",
      "    (linear_in): Linear(in_features=10, out_features=200, bias=True)\n",
      "    (linear_out): Linear(in_features=200, out_features=100, bias=True)\n",
      "  )\n",
      "  (act1): ReLU()\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (layer2): BottleneckCell(\n",
      "    (linear_in): Linear(in_features=2300, out_features=50, bias=True)\n",
      "    (linear_out): Linear(in_features=50, out_features=100, bias=True)\n",
      "  )\n",
      "  (act2): ReLU()\n",
      "  (layer3): Linear(in_features=100, out_features=9, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55b24e4768c240dca19233b2a26d9ee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54ff762006b34251a580fb3ec40179d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fea7f0c424f4a0c9c6499f2a300b989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-04 19:37:54] \u001b[32mIntermediate result: 0.0  (Index 2)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "153acffc23714018abfcdae8e3477de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-04 19:38:04] \u001b[32mIntermediate result: 0.0  (Index 3)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fda78b057164ec581d8ddc274cdf67b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-04 19:38:14] \u001b[32mIntermediate result: 0.0  (Index 4)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86176be80915432bbf95b7c2c8710ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-04 19:38:24] \u001b[32mIntermediate result: 0.0  (Index 5)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a9091907e6d405c901c13ace43a5e1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-04 19:38:34] \u001b[32mIntermediate result: 0.0  (Index 6)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from nni.nas.space import model_context\n",
    "\n",
    "with model_context(exported_arch):\n",
    "    final_model = MyModelSpace(in_feat, 100, num_classes)\n",
    "    # DartsSpace(width=16, num_cells=8, dataset='cifar')\n",
    "\n",
    "print(final_model)\n",
    "# train_loader = DataLoader(train_data, batch_size=96, num_workers=6)  # Use the original training data\n",
    "\n",
    "max_epochs = 100\n",
    "\n",
    "evaluator = Classification(\n",
    "    learning_rate = 1e-3,\n",
    "    weight_decay = 1e-4,\n",
    "    train_dataloaders = train_loader,\n",
    "    val_dataloaders = val_loader,\n",
    "    max_epochs = max_epochs,\n",
    "    gpus = 1,\n",
    "    export_onnx = False,          # Disable ONNX export for this experiment\n",
    "    fast_dev_run = False,   # Should be false for fully training\n",
    "    num_classes = num_classes,\n",
    ")\n",
    "\n",
    "evaluator.fit(final_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
